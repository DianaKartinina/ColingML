{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8c18584",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Работа с текстами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a383f07d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Задачи бинарной классификации\n",
    "    * Сентимент анализ (позитивный \\ негативный текст)\n",
    "    * Модель \"фильтр\" (спам\\не спам; текст по \"теме\"\\не по \"теме\")\n",
    "    * Детекция парафраз\n",
    "\n",
    "\n",
    "#### Задачи мультикласс классификации\n",
    "    * Тематическая классификация документов (классификация новостей)\n",
    "    * Распознавание сущностей\n",
    "\n",
    "#### Задачи кластеризации\n",
    "    * Поиск групп схожих текстов\n",
    "    * Тематическое моделирование\n",
    "\n",
    "#### Задача регрессии\n",
    "    * Предсказание оценки отзыва (1-5 звёзд)\n",
    "\n",
    "#### Задача генерации текста \\ языкового моделирования\n",
    "    * Машинный перевод\n",
    "    * Генерация парафраз\n",
    "    * Автозаполнение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e8fec5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Как представлять тексты в формате X?\n",
    "\n",
    "Датасет $\\{ (x_i, y_i) \\}_{i=1}^N $\n",
    "\n",
    "$X$ -- ?\n",
    "\n",
    "Каковы свойства X?\n",
    "\n",
    "* Фиксированный размер строчек в матрице\n",
    "* Столбцы представляют один и тот же признак"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328bdb28",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Основная идея: __словарь__ и его размерность.\n",
    "\n",
    "Один элемент словаря - один уникальный токен\n",
    "\n",
    "\n",
    "\"a quick brown fox jumped over the lazy dog. the cat sat on a mat.\"\n",
    "\n",
    "```python\n",
    "\n",
    "vocabulary = {\n",
    "        \"a\": 0,\n",
    "        \"the\": 1,\n",
    "        \"quick\": 2\n",
    "        \"brown\": 3\n",
    "        .\n",
    "        .\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0af964",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Как разбивать тексты на токены?\n",
    "\n",
    "text = `\"Blazingly fast tokenization\"`\n",
    "\n",
    "---\n",
    "\n",
    "* По правилам: razdel.tokenize, nltk.tokenize\n",
    "\n",
    "`[Blazingly, fast, tokenization]`\n",
    "\n",
    "\n",
    "----\n",
    "* Статистически: byte pair encoding\n",
    "\n",
    "`['▁Bl', 'az', 'ingly', '▁fast', '▁token', 'ization', '!']`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80717c9d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Основная цель  bpe - сокращение размера словаря без необходимости предобработки\n",
    "\n",
    "* Всего слов в русском языке: ~145k\n",
    "* Часто используемых слов: ~20k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8695a56f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Нормализация слов - ещё один способ сокращения размера словаря\n",
    "\n",
    "text = `\"прыгать прыгал, да не упрыгал\"`\n",
    "\n",
    "прыгать --> прыгать\n",
    "прыгал  --> прыгать\n",
    "упрыгал --> упрыгать (или тоже прыгать)\n",
    " \n",
    "```python\n",
    "\n",
    "vocabulary = {\n",
    "    \"прыгать\": 0,\n",
    "    \"да\": 1,\n",
    "    \"не\": 2\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a01a63",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Преобразование словаря в признаки\n",
    "\n",
    "```python\n",
    "corpus = [\n",
    "    \"the cat sat on the mat\",\n",
    "    \"the cat is on the window\",\n",
    "    \"we like the cat\"\n",
    "]\n",
    "\n",
    "word2idx = {\n",
    "    \"the\": 0,\n",
    "    \"cat\": 1,\n",
    "    \"sat\": 2,\n",
    "    \"on\": 3,\n",
    "    \"mat\": 4,\n",
    "    \"is\": 5,\n",
    "    \"window\": 6,\n",
    "    \"we\": 7,\n",
    "    \"like\": 8\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387b8bc1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "```\"the cat sat on the mat\" ```\n",
    "\n",
    "```[2 1 1 1 1 0 0 0 0]```\n",
    "\n",
    "\n",
    "```\n",
    "word2idx = {\n",
    "    \"the\": 0,\n",
    "    \"cat\": 1,\n",
    "    \"sat\": 2,\n",
    "    \"on\": 3,\n",
    "    \"mat\": 4,\n",
    "    \"is\": 5,\n",
    "    \"window\": 6,\n",
    "    \"we\": 7,\n",
    "    \"like\": 8\n",
    "}\n",
    "```\n",
    "\n",
    "```\"we like the cat\"``` --> ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ced1c65",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```мама мыла раму``` --> ```рама мыла маму```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a1c5f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?',\n",
    " ]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "vectorizer.get_feature_names_out()\n",
    "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
    "       'this'], )\n",
    "\n",
    "print(X.toarray())\n",
    "[[0 1 1 1 0 0 1 0 1]\n",
    " [0 2 0 1 0 1 1 0 1]\n",
    " [1 0 0 1 1 0 1 1 1]\n",
    " [0 1 1 1 0 0 1 0 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f05de794",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "X2 = vectorizer2.fit_transform(corpus)\n",
    "vectorizer2.get_feature_names_out()\n",
    "\n",
    "array(['and this', 'document is', 'first document', 'is the', 'is this',\n",
    "       'second document', 'the first', 'the second', 'the third', 'third one',\n",
    "       'this document', 'this is', 'this the'], ...)\n",
    "\n",
    "print(X2.toarray())\n",
    "[[0 0 1 1 0 0 1 0 0 0 0 1 0]\n",
    "[0 1 0 1 0 1 0 1 0 0 1 0 0]\n",
    "[1 0 0 1 0 0 0 0 1 1 0 1 0]\n",
    "[0 0 1 0 1 0 1 0 0 0 0 0 1]]\n",
    "\n",
    "# ТЕстовая выборка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dca49f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ещё одна проблема с мешком слов, что подход мешка слов не учитывает шум.\n",
    "Некоторые токены частотнее других (гораздо).\n",
    "\n",
    "Однако при этом мы не хотим терять информацию о частотных, но специфичных для некоторого текста токенах\n",
    "\n",
    "\n",
    "TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716364a6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Term Frequency (TF)\n",
    "\n",
    "Сколько раз слово встретилось в документе, делённое на общее число слов в документе\n",
    "\n",
    "$$tf_{ij} = \\frac{n_{ij}}{\\sum_{k}n_{ij}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d8d009",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Inverse Document Frequency (IDF)\n",
    "\n",
    "Число текстов делённое на количество текстов, которые содержат число w.\n",
    "\n",
    "Определяет вес редких слов среди документов в корпусе\n",
    "\n",
    "$$ idf(w) = log(\\frac{N}{df_{t}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9efff8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### TF-IDF\n",
    "\n",
    "Вес некоторого слова пропорционален частоте употребления этого слова в документе и обратно пропорционален частоте употребления слова во всех документах коллекции. \n",
    "\n",
    "$$ w_{ij} = tf_{ij} * log(\\frac{N}{df_{t}}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe5de5f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?',\n",
    " ]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "vectorizer.get_feature_names_out()\n",
    "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
    "       'this'], )\n",
    "print(X.shape)\n",
    "(4, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c2b237",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "\n",
    "    #    ... предобработка\n",
    "\n",
    "    ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', LogisticRegression()),\n",
    " ])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
